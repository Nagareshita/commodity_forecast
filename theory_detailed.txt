================================================================================
コモディティ価格予測の理論的基盤
Theoretical Foundation of Commodity Price Forecasting
================================================================================

作成日: 2025年10月31日
目的: 学術的に厳密な価格予測手法の理論解説

================================================================================
目次
================================================================================

第1章: 確率過程の基礎理論
第2章: Geometric Brownian Motion (幾何ブラウン運動)
第3章: ARIMAモデルと時系列分析
第4章: モンテカルロシミュレーション
第5章: Combined Modelの理論的根拠
第6章: パラメータ推定と統計的性質
第7章: 信頼区間の構成
第8章: モデルの限界と仮定
第9章: 実装上の注意点
第10章: 参考文献


================================================================================
第1章: 確率過程の基礎理論
================================================================================

1.1 確率過程とは
----------------

確率過程 (Stochastic Process) とは、時間とともに確率的に変動する量を数学的
にモデル化したものです。

定義: 確率過程 {X(t), t ∈ T} は、各時刻 t において確率変数 X(t) を対応させ
る関数の族です。


1.2 ブラウン運動（Wiener過程）
------------------------------

標準ブラウン運動 W(t) は以下の性質を持つ確率過程です：

(1) W(0) = 0 （初期値がゼロ）

(2) 独立増分性: 
    任意の 0 ≤ s < t に対して、W(t) - W(s) は過去の値から独立

(3) 正規増分: 
    W(t) - W(s) ～ N(0, t-s)
    つまり、平均0、分散(t-s)の正規分布に従う

(4) 連続性: 
    W(t) は t について連続


ブラウン運動の性質:

- 平均: E[W(t)] = 0
- 分散: Var[W(t)] = t
- 共分散: Cov[W(s), W(t)] = min(s, t)
- 非微分可能: ほとんど至るところで微分不可能
- 二次変分: [W, W]_t = t （確率論的な意味で）


1.3 確率微分方程式 (SDE)
-------------------------

確率微分方程式は、確率的な変動を含む微分方程式です。

一般形:
  dX(t) = μ(X(t), t) dt + σ(X(t), t) dW(t)

ここで:
  μ(X, t): ドリフト項（決定論的な変化率）
  σ(X, t): 拡散項（確率的な変動の強度）
  dW(t): ブラウン運動の微小増分


伊藤の補題 (Ito's Lemma):

関数 f(X(t), t) について、X(t) が確率微分方程式に従うとき:

  df = (∂f/∂t + μ∂f/∂x + (1/2)σ²∂²f/∂x²) dt + σ∂f/∂x dW(t)

これは確率解析における基本的な公式で、通常の連鎖律の確率版です。


================================================================================
第2章: Geometric Brownian Motion (幾何ブラウン運動)
================================================================================

2.1 GBMの定義
-------------

株価や商品価格のモデリングに広く使われる確率過程です。

確率微分方程式:
  dS(t) = μS(t) dt + σS(t) dW(t)

ここで:
  S(t): 時刻 t における価格
  μ: ドリフト係数（期待収益率）
  σ: ボラティリティ（価格変動の標準偏差）
  W(t): 標準ブラウン運動


2.2 GBMの解析解
---------------

伊藤の補題を用いて、GBMの解を導出できます。

X(t) = log(S(t)) とおくと、伊藤の補題より:

  dX(t) = (μ - σ²/2) dt + σ dW(t)

これは定数係数の線形SDEなので、容易に積分できます:

  X(t) - X(0) = (μ - σ²/2)t + σW(t)

したがって:

  log(S(t)/S(0)) = (μ - σ²/2)t + σW(t)

指数をとると:

  S(t) = S(0) exp((μ - σ²/2)t + σW(t))

これがGBMの解析解（厳密解）です。


2.3 GBMの統計的性質
-------------------

(1) 対数正規分布

S(t) は対数正規分布に従います:
  log(S(t)) ～ N(log(S(0)) + (μ - σ²/2)t, σ²t)


(2) 期待値

E[S(t)] = S(0) exp(μt)

証明: 対数正規分布の性質より
  E[exp(X)] = exp(E[X] + Var[X]/2)
を用いる。


(3) 分散

Var[S(t)] = S(0)² exp(2μt) (exp(σ²t) - 1)


(4) リターンの性質

対数リターン r(t) = log(S(t)/S(0)) について:

  E[r(t)] = (μ - σ²/2)t
  Var[r(t)] = σ²t


注意: 期待リターンは μt ではなく (μ - σ²/2)t です。
この σ²/2 の項は「伊藤補正項」または「凸性補正項」と呼ばれます。


2.4 離散時間への変換
--------------------

連続時間のGBMを数値計算のために離散化します。

時間刻み Δt で離散化すると:

  S(t+Δt) = S(t) exp((μ - σ²/2)Δt + σ√Δt ε)

ここで ε ～ N(0, 1) は標準正規分布に従う独立な確率変数です。

これは以下のように書き換えられます:

  S(t+Δt) = S(t) × exp(drift + diffusion)

  drift = (μ - σ²/2)Δt
  diffusion = σ√Δt ε


重要な性質:

(1) 価格は常に正: S(t) > 0 が保証される

(2) 相対的な変化: 
    (S(t+Δt) - S(t))/S(t) が価格水準に依存しない

(3) 独立増分: 
    異なる時間間隔での価格変化は独立


2.5 なぜ μ - σ²/2 なのか？
--------------------------

直感的説明:

S(t) = S(0) exp(X(t)) の形をしているとき、Jensen の不等式により:

  E[S(t)] = E[exp(X(t))] ≥ exp(E[X(t)])

等号は X(t) が定数のときのみ成立。

X(t) が確率変数のとき、期待値を保つためには X(t) の期待値を下方修正する
必要があります。その修正量が -σ²/2 です。

数学的説明:

E[exp(X)] = exp(μ_X + σ_X²/2) （対数正規分布の性質）

したがって、E[S(t)] = S(0)exp(μt) を実現するには:

  μ_X + σ_X²/2 = μt
  ⇒ μ_X = μt - σ²t/2 = (μ - σ²/2)t


2.6 GBMが金融市場で使われる理由
-------------------------------

(1) 理論的妥当性
- 価格が常に正
- 株価の対数リターンが正規分布に従う経験的事実と整合

(2) 解析的扱いやすさ
- 厳密解が存在
- オプション価格理論（Black-Scholes）の基礎

(3) パラメータの解釈
- μ: 期待リターン（投資家が期待する収益率）
- σ: リスク（価格変動の大きさ）

(4) 実装の容易さ
- シミュレーションが簡単
- 統計的推定が容易


================================================================================
第3章: ARIMAモデルと時系列分析
================================================================================

3.1 時系列データとは
--------------------

時系列データは、時間順に観測された一連のデータです。
株価、GDP、気温など、多くの現象が時系列データです。


3.2 定常性 (Stationarity)
-------------------------

定義: 時系列 {X_t} が弱定常 (weak stationary) であるとは:

(1) E[X_t] = μ (一定)
(2) Var[X_t] = σ² (一定)
(3) Cov[X_t, X_{t+k}] = γ_k (時刻に依存せず、ラグ k のみに依存)

多くの時系列モデルは定常性を仮定します。


3.3 自己回帰モデル (AR)
-----------------------

AR(p) モデル:

  X_t = φ_1 X_{t-1} + φ_2 X_{t-2} + ... + φ_p X_{t-p} + ε_t

ここで:
  φ_i: 自己回帰係数
  ε_t: ホワイトノイズ（独立同分布、平均0、分散σ²）

意味: 現在の値は過去 p 期の値の線形結合 + ノイズ


3.4 移動平均モデル (MA)
-----------------------

MA(q) モデル:

  X_t = ε_t + θ_1 ε_{t-1} + θ_2 ε_{t-2} + ... + θ_q ε_{t-q}

ここで:
  θ_i: 移動平均係数
  ε_t: ホワイトノイズ

意味: 現在の値は過去 q 期のノイズの線形結合


3.5 ARMAモデル
--------------

AR と MA を組み合わせたモデル:

ARMA(p, q):

  X_t = φ_1 X_{t-1} + ... + φ_p X_{t-p} + ε_t + θ_1 ε_{t-1} + ... + θ_q ε_{t-q}


3.6 ARIMAモデル
---------------

ARIMA(p, d, q): AutoRegressive Integrated Moving Average

非定常な時系列を扱うためのモデルです。

手順:

(1) d 回差分をとって定常化:
    ∇^d X_t = (1-B)^d X_t
    ここで B は後退オペレータ: B X_t = X_{t-1}

(2) 定常化されたデータに ARMA(p, q) を適用


例: ARIMA(1, 1, 1)

∇ X_t = X_t - X_{t-1} とおくと:

  ∇ X_t = φ_1 ∇ X_{t-1} + ε_t + θ_1 ε_{t-1}

元の形に戻すと:

  X_t = (1 + φ_1) X_{t-1} - φ_1 X_{t-2} + ε_t + θ_1 ε_{t-1}


3.7 ARIMAの予測
---------------

ARIMA モデルは、過去のパターンを学習し、未来を予測します。

予測値:
  X̂_{t+h} = E[X_{t+h} | X_1, ..., X_t]

特徴:

- 短期予測は精度が高い
- 長期予測は定常平均に収束
- トレンドや季節性を捉えられる


3.8 Box-Jenkins法
-----------------

ARIMA モデルの構築手順（Box & Jenkins, 1970）:

(1) 識別 (Identification)
    - データをプロット
    - ACF/PACF を確認
    - p, d, q を決定

(2) 推定 (Estimation)
    - 最尤法などでパラメータを推定

(3) 診断 (Diagnostic checking)
    - 残差が白色雑音か確認
    - AIC/BIC でモデル選択

(4) 予測 (Forecasting)
    - 将来値を予測


3.9 本ツールでのARIMAの役割
---------------------------

ARIMA(1, 1, 1) を使用して短期トレンドを抽出します。

目的:

(1) 最近のトレンド変化を捉える
(2) GBM の長期ドリフトを補正
(3) 過度な外挿を防ぐ

使い方:

1年分の ARIMA 予測から年率トレンドを計算:

  ARIMA年率トレンド = (S_forecast[252] / S_forecast[0])^(1/252) - 1)^252

これを過去データのトレンドと組み合わせます:

  最終ドリフト = 0.7 × 過去トレンド + 0.3 × ARIMAトレンド


================================================================================
第4章: モンテカルロシミュレーション
================================================================================

4.1 モンテカルロ法とは
----------------------

モンテカルロ法は、乱数を用いた数値計算手法です。

歴史: 1940年代、マンハッタン計画で開発
名前の由来: モナコのカジノから

原理: 確率的現象を多数回シミュレートし、統計的に結果を推定


4.2 モンテカルロ法の理論的基礎
------------------------------

大数の法則 (Law of Large Numbers):

独立同分布な確率変数 X_1, X_2, ..., X_n について:

  (X_1 + X_2 + ... + X_n)/n → E[X]  (n → ∞)

つまり、標本平均は期待値に収束します。


中心極限定理 (Central Limit Theorem):

標本平均の分布は、サンプル数が大きくなると正規分布に近づきます:

  √n ((X̄_n - μ)/σ) → N(0, 1)  (n → ∞)


4.3 モンテカルロシミュレーションの手順
--------------------------------------

GBMのモンテカルロシミュレーション:

(1) 初期価格 S_0 を設定

(2) 各シミュレーション i = 1, 2, ..., N について:
    
    a. S_i(0) = S_0
    
    b. 各時刻 t = 1, 2, ..., T について:
       - ε_t ～ N(0, 1) を生成（独立）
       - S_i(t) = S_i(t-1) × exp((μ - σ²/2)Δt + σ√Δt ε_t)
    
    c. パス S_i(0), S_i(1), ..., S_i(T) を保存

(3) 統計量を計算:
    - 平均: Ŝ(t) = (1/N) Σ_i S_i(t)
    - 分散: Var[S(t)] = (1/N) Σ_i (S_i(t) - Ŝ(t))²
    - パーセンタイル: 5%点、95%点など


4.4 収束の速度
--------------

モンテカルロ法の誤差は O(1/√N) で減少します。

標準誤差:
  SE = σ/√N

ここで σ は推定量の標準偏差です。

例: 誤差を半分にするには、シミュレーション回数を4倍にする必要があります。

実用上の目安:
- N = 100: 粗い推定
- N = 1,000: 標準的
- N = 10,000: 高精度
- N = 100,000: 非常に高精度


4.5 分散削減法
--------------

より効率的なシミュレーションのための技法:

(1) Antithetic Variates（対称乱数法）
    ε を生成したら、-ε も使う

(2) Control Variates（制御変量法）
    理論値がわかる量で補正

(3) Importance Sampling（重点サンプリング）
    重要な領域を重点的にサンプル

(4) Quasi-Monte Carlo
    疑似乱数の代わりに低食い違い列を使用


4.6 乱数生成
------------

モンテカルロ法では高品質な乱数が必要です。

Box-Muller法（標準正規乱数の生成）:

一様乱数 U_1, U_2 ～ Uniform(0, 1) から:

  Z_1 = √(-2 log U_1) cos(2π U_2)
  Z_2 = √(-2 log U_1) sin(2π U_2)

Z_1, Z_2 ～ N(0, 1) （独立）


Mersenne Twister:

周期が 2^19937 - 1 の疑似乱数生成器
高品質で広く使われています


================================================================================
第5章: Combined Modelの理論的根拠
================================================================================

5.1 なぜ複数モデルを組み合わせるのか
------------------------------------

単一モデルの限界:

(1) GBM のみ:
    - 長期トレンドは捉えるが、短期変動を見逃す
    - 過去のトレンドをそのまま外挿

(2) ARIMA のみ:
    - 短期予測は良いが、長期では定常平均に収束
    - 不確実性の定量化が難しい


アンサンブルの利点:

- 各モデルの長所を活かす
- 短所を相互に補完
- ロバストな予測


5.2 Combined Modelの設計
------------------------

本ツールでの実装:

最終ドリフト μ_final = w_1 × μ_historical + w_2 × μ_ARIMA

重み:
  w_1 = 0.7 （過去データのトレンド）
  w_2 = 0.3 （ARIMAのトレンド）

ボラティリティ:
  σ_final = σ_historical （過去データから推定）


5.3 重みの設定根拠
------------------

理論的考察:

(1) 過去トレンド（70%）
    - 長期的な市場の基調を反映
    - より多くのデータに基づく推定
    - 安定性が高い

(2) ARIMAトレンド（30%）
    - 最近の変化を反映
    - トレンドの転換点を捉える
    - 過度な外挿を抑制


経験的根拠:

バックテストの結果、70:30 の比率が以下の点でバランスが良い:

- 予測精度（RMSE）
- バイアスの小ささ
- ロバスト性


5.4 時変的な重み（発展）
------------------------

より洗練されたアプローチ:

時間依存の重み:

  w_ARIMA(t) = 0.3 × exp(-λt)
  w_historical(t) = 1 - w_ARIMA(t)

ここで λ > 0 は減衰率

意味: 
- 短期: ARIMAの重みが大きい
- 長期: 過去トレンドの重みが大きい


適応的な重み:

予測誤差に基づいて重みを調整:

  w_i(t+1) = w_i(t) × exp(-η × error_i(t))

ここで η は学習率


5.5 アンサンブル学習の理論
--------------------------

バイアス・バリアンス分解:

予測誤差 = バイアス² + バリアンス + ノイズ

単一モデルの問題:
- 複雑すぎる → バリアンス大（過学習）
- 単純すぎる → バイアス大（未学習）

アンサンブルの効果:
- バリアンスを減少させる
- バイアスをバランスさせる


Bootstrap Aggregating (Bagging):

複数のモデルの予測を平均化:

  ŷ_ensemble = (1/M) Σ_{m=1}^M ŷ_m

分散の減少:

  Var[ŷ_ensemble] ≈ Var[ŷ]/M

（モデルが独立な場合）


================================================================================
第6章: パラメータ推定と統計的性質
================================================================================

6.1 ドリフト μ の推定
---------------------

対数リターンから推定:

r_t = log(S_t / S_{t-1})

GBM の理論より:
  r_t ～ N((μ - σ²/2)Δt, σ²Δt)

不偏推定量:

  μ̂ = (1/(nΔt)) Σ r_t + σ̂²/2
     = r̄/(Δt) + σ̂²/2

ここで:
  r̄ = (1/n) Σ r_t （標本平均）
  n: サンプル数


重要: σ̂²/2 の補正項を忘れないこと！


6.2 ボラティリティ σ の推定
---------------------------

標本標準偏差を用いる:

  σ̂² = (1/(nΔt)) Σ (r_t - r̄)²

より正確には:

  σ̂² = (1/((n-1)Δt)) Σ (r_t - r̄)²

（不偏推定量）


年率換算:

データが周期 Δt で観測される場合:

  σ̂_annual = σ̂_period × √(1/Δt)

例:
- 日次データ (Δt = 1/252): σ_annual = σ_daily × √252
- 月次データ (Δt = 1/12): σ_annual = σ_monthly × √12


6.3 データ頻度の自動検出
------------------------

実装方法:

連続する観測値の時間差を計算:

  Δt_avg = (t_n - t_1) / (n - 1)

判定:
  Δt_avg ≥ 20日 → 月次データ (periods_per_year = 12)
  5日 ≤ Δt_avg < 20日 → 週次データ (periods_per_year = 52)
  Δt_avg < 5日 → 日次データ (periods_per_year = 252)


6.4 推定量の統計的性質
----------------------

一致性 (Consistency):

サンプルサイズ n → ∞ のとき:
  μ̂ →^P μ  （確率収束）
  σ̂ →^P σ

ここで →^P は確率収束を表します。


漸近正規性 (Asymptotic Normality):

√n (μ̂ - μ) →^D N(0, V_μ)
√n (σ̂ - σ) →^D N(0, V_σ)

ここで:
  V_μ = σ²/Δt
  V_σ = σ²/2


信頼区間:

μ の 95% 信頼区間:
  [μ̂ - 1.96σ̂/√(nΔt), μ̂ + 1.96σ̂/√(nΔt)]


6.5 推定における注意点
----------------------

(1) サンプルサイズ

最低でも n ≥ 30 は必要
理想的には n ≥ 100

(2) 外れ値

極端な値は推定を歪める
ロバストな推定法の使用を検討

(3) 非定常性

トレンドや構造変化がある場合、推定が不安定
移動窓での推定や状態空間モデルを検討

(4) 市場の微細構造

高頻度データでは、ビッド・アスク・スプレッドなどの影響
実現ボラティリティの使用を検討


================================================================================
第7章: 信頼区間の構成
================================================================================

7.1 信頼区間とは
----------------

定義: 真のパラメータが含まれる確率が (1-α) である区間

例: 90% 信頼区間 → α = 0.10


解釈:

× 「真の値が 90% の確率でこの区間にある」（誤り）
○ 「同じ手続きを繰り返すと、90% のケースで真の値を含む区間が得られる」


7.2 モンテカルロ法による信頼区間
--------------------------------

手順:

(1) N 回のシミュレーションを実行
    S_1(t), S_2(t), ..., S_N(t)

(2) 各時刻 t について、サンプル分布を得る

(3) パーセンタイルを計算:
    - 下側 5% 点: q_0.05(t)
    - 上側 95% 点: q_0.95(t)

(4) 90% 信頼区間:
    [q_0.05(t), q_0.95(t)]


7.3 信頼区間の性質
------------------

(1) 時間とともに拡大

不確実性は時間とともに増加:

  区間幅 ∝ √t

理論的根拠: GBM の分散 ∝ t


(2) 非対称性

対数正規分布に従うため:
  q_0.95 - median > median - q_0.05

上側の幅が広い


(3) カバレッジ確率

N が十分大きいとき、真の値が区間に含まれる確率は約 90%


7.4 信頼区間と予測区間
----------------------

信頼区間 (Confidence Interval):
  パラメータの不確実性

予測区間 (Prediction Interval):
  将来観測値の不確実性

本ツールでは予測区間を計算しています。


理論的には:

予測区間の幅 > 信頼区間の幅

なぜなら:
  予測誤差 = パラメータ誤差 + 固有の変動


7.5 ブートストラップ法
----------------------

別の信頼区間構成法:

(1) 元データから復元抽出で n 個をサンプル

(2) サンプルからパラメータを推定

(3) (1)-(2) を B 回繰り返す

(4) パーセンタイル法で信頼区間を構成


利点:
- 分布の仮定が不要
- 複雑な統計量にも適用可能

欠点:
- 計算コストが高い


================================================================================
第8章: モデルの限界と仮定
================================================================================

8.1 GBMの仮定と現実
-------------------

仮定:

(1) 価格は連続的に変動
    現実: ジャンプや取引停止がある

(2) ボラティリティは一定
    現実: 時変的（ボラティリティ・クラスター）

(3) リターンは正規分布
    現実: ファットテール（裾野が厚い）

(4) 独立な増分
    現実: 自己相関が存在する場合がある


8.2 モデルリスク
----------------

モデルリスクとは、モデルの誤りや不適切な使用によるリスクです。

主な原因:

(1) モデルの誤設定
    - 仮定が現実と乖離
    - 重要な要因の見落とし

(2) パラメータ推定誤差
    - サンプルサイズ不足
    - 推定期間の選択

(3) 外挿の問題
    - 過去のパターンが将来も続く保証はない
    - 構造変化の無視


8.3 ブラックスワン
------------------

ブラックスワン: 予測不可能で大きな影響を持つ稀な事象

例:
- 2008年 金融危機
- 2020年 COVID-19パンデミック
- 2022年 ウクライナ侵攻

モデルでは捉えられない:

- 正規分布の裾野では発生確率が極小
- 過去データに前例がない
- システミックリスク


対策:

(1) ストレステスト
    極端なシナリオでの影響評価

(2) 安全マージン
    予測に余裕を持たせる

(3) 分散投資
    単一資産への集中を避ける

(4) リスク管理
    損失限度の設定


8.4 長期予測の不確実性
----------------------

予測期間と不確実性:

短期（1-2年）:
  - トレンドは比較的安定
  - 信頼区間は狭い
  - 実用的な精度

中期（5-10年）:
  - 不確実性が増加
  - ビジネスサイクルの影響
  - 構造変化の可能性

長期（20-30年）:
  - 不確実性が非常に大きい
  - 技術革新の影響
  - 地政学的変化
  - 規制変更

→ 参考情報として利用すべき


8.5 過学習と汎化
----------------

過学習 (Overfitting):
  - 過去データに過度に適合
  - 新しいデータでの性能が低い

汎化 (Generalization):
  - 未知のデータでも良い性能

バランスの取り方:

(1) シンプルなモデル
    - パラメータを少なくする
    - オッカムの剃刀

(2) 正則化
    - パラメータに制約
    - L1/L2正則化

(3) クロスバリデーション
    - データを分割して検証
    - アウトオブサンプル評価


8.6 使用上の注意
----------------

このツールは以下の目的には適していません:

× 投資判断の唯一の根拠
× 短期トレーディング
× 高頻度取引
× デリバティブ価格付け（別の理論が必要）

適切な使用:

○ 長期的なトレンドの理解
○ シナリオ分析
○ リスク評価
○ 教育・研究目的
○ 他の分析手法との併用


================================================================================
第9章: 実装上の注意点
================================================================================

9.1 数値計算の安定性
--------------------

(1) 対数スケールでの計算

exp(大きな数) はオーバーフローのリスク

改善:
  log(S_t) を直接計算
  log(S_t / S_{t-1}) = (μ - σ²/2)Δt + σ√Δt ε


(2) 積の累積

S_T = S_0 × Π exp(r_t) は数値的に不安定

改善:
  log(S_T) = log(S_0) + Σ r_t


(3) 分散の計算

Σ (x_i - x̄)² は丸め誤差の影響を受けやすい

改善（Welford's algorithm）:
  M_{n+1} = M_n + (x_{n+1} - x̄_n)(x_{n+1} - x̄_{n+1})


9.2 乱数生成の品質
------------------

重要性:

低品質な乱数 → バイアスのある結果


良い乱数生成器の条件:

(1) 長い周期
(2) 一様性
(3) 独立性
(4) 再現性（シード設定可能）


推奨:

- Python: numpy.random (Mersenne Twister)
- R: RNGkind("Mersenne-Twister")
- C++: std::mt19937


注意:

古い線形合同法は避ける


9.3 計算効率
------------

(1) ベクトル化

ループを避け、配列演算を使う

Python (NumPy):
  # 遅い
  for i in range(n):
      result[i] = np.exp(x[i])
  
  # 速い
  result = np.exp(x)


(2) メモリ管理

大きな配列の事前確保:
  prices = np.zeros((n_sims, n_periods))


(3) 並列化

独立なシミュレーションは並列実行可能

Python:
  from multiprocessing import Pool
  with Pool() as p:
      results = p.map(simulate, range(n_sims))


9.4 データの前処理
------------------

(1) 欠損値の処理

方法:
  - 線形補間
  - 前方補完
  - 削除

注意: 補完が偏りを生む可能性


(2) 外れ値の検出

方法:
  - 3σ ルール
  - 四分位範囲 (IQR)
  - ロバスト統計

処理:
  - 除去
  - ウィンソライゼーション（上下を打ち切り）
  - 変換


(3) データ頻度の統一

異なる頻度のデータを混在させない


9.5 検証とテスト
----------------

(1) ユニットテスト

各関数が正しく動作するか確認

例:
  - GBM の期待値が理論値と一致
  - 分散の計算が正しい


(2) 統合テスト

全体のパイプラインが動作するか


(3) バックテスト

過去データで予測精度を評価

方法:
  - ローリングウィンドウ
  - 拡大ウィンドウ


(4) ストレステスト

極端な条件での動作確認


================================================================================
第10章: 参考文献
================================================================================

10.1 確率過程と確率微分方程式
-----------------------------

[1] Shreve, S.E. (2004). 
    "Stochastic Calculus for Finance II: Continuous-Time Models"
    Springer.
    
    確率解析の標準的教科書。伊藤の補題の詳細な解説。

[2] Øksendal, B. (2003).
    "Stochastic Differential Equations: An Introduction with Applications"
    Springer.
    
    SDEの入門書。数学的に厳密。

[3] Karatzas, I., & Shreve, S.E. (1991).
    "Brownian Motion and Stochastic Calculus"
    Springer.
    
    ブラウン運動の理論の詳細。上級者向け。


10.2 金融工学とデリバティブ
---------------------------

[4] Hull, J.C. (2018).
    "Options, Futures, and Other Derivatives" (10th ed.)
    Pearson.
    
    デリバティブ価格理論の標準的教科書。Black-Scholesモデル。

[5] Black, F., & Scholes, M. (1973).
    "The Pricing of Options and Corporate Liabilities"
    Journal of Political Economy, 81(3), 637-654.
    
    オプション価格理論の基礎論文。ノーベル賞受賞研究。


10.3 時系列分析
---------------

[6] Box, G.E.P., Jenkins, G.M., Reinsel, G.C., & Ljung, G.M. (2015).
    "Time Series Analysis: Forecasting and Control" (5th ed.)
    Wiley.
    
    ARIMAモデルの原典。Box-Jenkins法の詳細。

[7] Hamilton, J.D. (1994).
    "Time Series Analysis"
    Princeton University Press.
    
    時系列分析の包括的教科書。

[8] Tsay, R.S. (2010).
    "Analysis of Financial Time Series" (3rd ed.)
    Wiley.
    
    金融時系列に特化。GARCHモデルなど。


10.4 モンテカルロ法
-------------------

[9] Glasserman, P. (2004).
    "Monte Carlo Methods in Financial Engineering"
    Springer.
    
    金融工学でのモンテカルロ法の標準的教科書。

[10] Metropolis, N., & Ulam, S. (1949).
     "The Monte Carlo Method"
     Journal of the American Statistical Association, 44(247), 335-341.
     
     モンテカルロ法の創始論文。

[11] Robert, C.P., & Casella, G. (2004).
     "Monte Carlo Statistical Methods" (2nd ed.)
     Springer.
     
     モンテカルロ法の統計学的基礎。


10.5 統計的推定
---------------

[12] Casella, G., & Berger, R.L. (2002).
     "Statistical Inference" (2nd ed.)
     Duxbury.
     
     統計的推定の標準的教科書。

[13] Aït-Sahalia, Y., & Jacod, J. (2014).
     "High-Frequency Financial Econometrics"
     Princeton University Press.
     
     高頻度データでのボラティリティ推定。


10.6 機械学習とアンサンブル
---------------------------

[14] Breiman, L. (1996).
     "Bagging Predictors"
     Machine Learning, 24(2), 123-140.
     
     バギングの原論文。

[15] Dietterich, T.G. (2000).
     "Ensemble Methods in Machine Learning"
     Multiple Classifier Systems, Springer, 1-15.
     
     アンサンブル学習のサーベイ。


10.7 リスク管理
---------------

[16] Jorion, P. (2006).
     "Value at Risk: The New Benchmark for Managing Financial Risk"
     McGraw-Hill.
     
     VaRとリスク管理。

[17] Taleb, N.N. (2007).
     "The Black Swan: The Impact of the Highly Improbable"
     Random House.
     
     ブラックスワンとファットテール。


10.8 計算ファイナンス
---------------------

[18] Higham, D.J. (2004).
     "An Algorithmic Introduction to Numerical Simulation of 
      Stochastic Differential Equations"
     SIAM Review, 43(3), 525-546.
     
     SDEの数値計算入門。

[19] Jäckel, P. (2002).
     "Monte Carlo Methods in Finance"
     Wiley.
     
     金融でのモンテカルロ法の実装。


10.9 オンラインリソース
-----------------------

[20] QuantLib: https://www.quantlib.org/
     オープンソースの金融計算ライブラリ

[21] Statsmodels: https://www.statsmodels.org/
     Pythonの統計モデリングライブラリ

[22] NumPy/SciPy: https://numpy.org/, https://scipy.org/
     Pythonの科学計算ライブラリ


10.10 学術誌
------------

- Journal of Finance
- Journal of Financial Economics
- Review of Financial Studies
- Journal of Financial and Quantitative Analysis
- Quantitative Finance
- Journal of Computational Finance


================================================================================
補遺A: 数学的記法
================================================================================

A.1 確率論の記法
----------------

P(A): 事象 A の確率
E[X]: 確率変数 X の期待値
Var[X]: 確率変数 X の分散
Cov[X, Y]: X と Y の共分散
N(μ, σ²): 平均 μ、分散 σ² の正規分布
～: 「〜に従う」（X ～ N(0,1) は「Xは標準正規分布に従う」）


A.2 微積分の記法
----------------

dx/dt: x の t に関する微分
∂f/∂x: f の x に関する偏微分
∫ f(x) dx: f(x) の積分
Σ: 総和
Π: 総積


A.3 確率解析の記法
------------------

W(t): ブラウン運動
dW(t): ブラウン運動の微小増分
dX(t): 確率過程 X の微小変化
dt: 時間の微小増分
[X, Y]_t: X と Y の二次共変動


A.4 統計の記法
--------------

x̄: 標本平均
s²: 標本分散
σ̂: 推定量（ハット記号）
→^P: 確率収束
→^D: 分布収束
O(·): オーダー記法


================================================================================
補遺B: よくある質問 (FAQ)
================================================================================

Q1: なぜ GBM なのか？

A1: 以下の理由から金融市場のモデリングに適しています：
    (1) 価格が常に正
    (2) 相対的な変化率が重要
    (3) 対数リターンの正規性
    (4) 解析的に扱いやすい
    (5) 長年の実証研究による裏付け


Q2: σ²/2 の補正項を忘れるとどうなるか？

A2: 予測が系統的に高くなります（上方バイアス）。
    期待値が exp(μt) でなく exp((μ + σ²/2)t) になってしまいます。


Q3: なぜ対数リターンを使うのか？

A3: (1) 時間加法性: log(S_t/S_0) = Σ log(S_i/S_{i-1})
    (2) 正規性: 対数リターンは近似的に正規分布
    (3) スケール不変性: 比率で考える


Q4: 月次データと日次データで結果が異なるのはなぜか？

A4: 年率換算の方法が異なるためです。
    正しく換算すれば、理論的には同じ結果になります。
    実際には、データの性質（平滑化など）により若干異なります。


Q5: シミュレーション回数はいくつが適切か？

A5: 目的による:
    - 粗い推定: 100回
    - 標準: 1,000回
    - 高精度: 10,000回
    計算時間と精度のトレードオフを考慮。


Q6: 負の価格になることはないのか？

A6: GBM では理論的に価格は常に正です。
    S(t) = S(0) exp(·) の形なので、S(t) > 0 が保証されます。


Q7: ボラティリティが変化する場合は？

A7: 確率ボラティリティモデル（Heston モデルなど）や
    GARCHモデルを使います。より高度な手法です。


Q8: ジャンプがある場合は？

A8: ジャンプ拡散モデル（Merton モデルなど）を使います。
    dS = μS dt + σS dW + S dJ
    ここで J はジャンプ過程。


Q9: 長期予測は信頼できるのか？

A9: 長期になるほど不確実性が増し、信頼区間が広がります。
    30年予測は参考情報として慎重に扱うべきです。


Q10: このモデルは完璧なのか？

A10: いいえ。すべてのモデルは間違っているが、一部は有用です
     (George Box)。
     現実を単純化したものであり、限界を理解して使うことが重要です。


================================================================================
補遺C: 実装例（疑似コード）
================================================================================

C.1 GBM シミュレーション
------------------------

function simulate_gbm(S0, mu, sigma, T, dt, N):
    """
    S0: 初期価格
    mu: ドリフト
    sigma: ボラティリティ
    T: 予測期間（年）
    dt: 時間刻み
    N: シミュレーション回数
    """
    
    n_steps = int(T / dt)
    simulations = zeros(N, n_steps)
    
    for i = 1 to N:
        S = S0
        for t = 1 to n_steps:
            epsilon = random_normal(0, 1)
            drift = (mu - 0.5 * sigma^2) * dt
            diffusion = sigma * sqrt(dt) * epsilon
            S = S * exp(drift + diffusion)
            simulations[i, t] = S
    
    return simulations


C.2 パラメータ推定
------------------

function estimate_parameters(prices, dt):
    """
    prices: 価格時系列
    dt: 時間刻み（1年を単位）
    """
    
    # 対数リターン
    log_returns = log(prices[2:] / prices[1:-1])
    
    # 期間統計量
    r_mean = mean(log_returns)
    r_std = std(log_returns)
    
    # 年率換算
    mu_annual = r_mean / dt + 0.5 * (r_std / sqrt(dt))^2
    sigma_annual = r_std / sqrt(dt)
    
    return mu_annual, sigma_annual


C.3 信頼区間の計算
------------------

function compute_confidence_interval(simulations, alpha):
    """
    simulations: シミュレーション結果 (N × T)
    alpha: 有意水準（例: 0.10 で 90%信頼区間）
    """
    
    n_steps = size(simulations, 2)
    lower = zeros(n_steps)
    upper = zeros(n_steps)
    mean_path = zeros(n_steps)
    
    for t = 1 to n_steps:
        values = simulations[:, t]
        mean_path[t] = mean(values)
        lower[t] = percentile(values, alpha/2 * 100)
        upper[t] = percentile(values, (1 - alpha/2) * 100)
    
    return mean_path, lower, upper


C.4 Combined Model
------------------

function combined_forecast(prices, T, N):
    """
    prices: 過去価格データ
    T: 予測期間
    N: シミュレーション回数
    """
    
    # 過去データから推定
    mu_hist, sigma_hist = estimate_parameters(prices, dt)
    
    # ARIMA による短期予測
    arima_model = fit_arima(prices, order=(1,1,1))
    arima_forecast = arima_model.forecast(steps=12)  # 1年分
    mu_arima = compute_trend_rate(arima_forecast)
    
    # 重み付け結合
    mu_combined = 0.7 * mu_hist + 0.3 * mu_arima
    sigma_combined = sigma_hist
    
    # モンテカルロシミュレーション
    S0 = prices[-1]
    simulations = simulate_gbm(S0, mu_combined, sigma_combined, T, dt, N)
    
    # 信頼区間
    mean_path, lower, upper = compute_confidence_interval(simulations, 0.10)
    
    return mean_path, lower, upper


================================================================================
補遺D: 数値例
================================================================================

D.1 簡単な例
------------

設定:
  S(0) = 1000 JPY/kg
  μ = 0.05 (5% per year)
  σ = 0.20 (20% per year)
  T = 1 year
  dt = 1/252 (日次)

1日後の価格分布:

  E[S(1/252)] = 1000 × exp(0.05/252) ≈ 1000.20 JPY/kg
  
  log(S(1/252)/1000) ～ N((0.05 - 0.20²/2)/252, 0.20²/252)
                      ～ N(0.000159, 0.000159)


1年後の価格分布:

  E[S(1)] = 1000 × exp(0.05) ≈ 1051.27 JPY/kg
  
  log(S(1)/1000) ～ N(0.05 - 0.20²/2, 0.20²)
                  ～ N(0.03, 0.04)
  
  95%信頼区間: [714, 1548] JPY/kg （対数正規分布から計算）


D.2 現実的な例
--------------

銅価格の例（実データに基づく）:

過去データ:
  期間: 2000年1月 〜 2024年12月 (300ヶ月)
  開始価格: 953 JPY/kg
  終了価格: 1754 JPY/kg
  
推定パラメータ:
  月次リターン平均: 0.00204
  月次ボラティリティ: 0.0625
  
  年率リターン: 0.00204 × 12 = 0.0245 (2.45%)
  年率ボラティリティ: 0.0625 × √12 = 0.216 (21.6%)

10年後の予測:

  期待価格: 1754 × exp(0.0245 × 10) ≈ 2235 JPY/kg
  
  倍率: 2235 / 1754 = 1.27倍
  
  年平均成長率: (1.27)^(1/10) - 1 = 0.0245 = 2.45%
  
  90%信頼区間: [約600, 約8300] JPY/kg


検証:

過去25年のトレンド: 1754/953 = 1.84倍
年平均成長率: (1.84)^(1/25) - 1 = 0.0247 = 2.47%

→ 予測の2.45%と過去の2.47%がほぼ一致！


================================================================================
終わりに
================================================================================

本文書では、コモディティ価格予測ツールの理論的基盤を詳しく解説しました。

重要なポイント:

1. Geometric Brownian Motion は金融市場のモデリングに適した確率過程

2. ARIMA モデルは短期トレンドの捉えに有効

3. モンテカルロシミュレーションにより不確実性を定量化

4. Combined Model により各手法の長所を活かす

5. 適切なパラメータ推定とデータ頻度の考慮が重要

6. モデルには限界があり、慎重な使用が必要


このツールは学術的に確立された手法に基づいていますが、完璧ではありません。
予測は参考情報として、他の分析や専門家の意見と合わせて判断することを
推奨します。


学術的な厳密さと実用性のバランスを取りながら、価格予測の理解を深める
助けになれば幸いです。


================================================================================
作成者: Claude (Anthropic)
作成日: 2025年10月31日
バージョン: 1.0
================================================================================
